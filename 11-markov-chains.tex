\chapter{Markov Chains}

Worked on by Akash

Let's first recall the definition of independent trials.
\begin{definition}[Independent trials]
A set of possible outcomes $E_1,E_2,...$ is given. With each outcome $E_k$ there is associated a probability $p_k$. The probability of a sampled sequence is defined as
$$ P\{(E_{j_0},E_{j_1},...,E_{j_k})\} = p_{j_0} p_{j_1} \hdots p_{j_k}$$
\end{definition}

\medskip
\noindent In the theory of Markov Chains the outcome of any trial depends on the outcome of the directly preceding trial only. 

\medskip
\noindent \textbf{Conditional probability}
\begin{itemize}
    \item $p_{jk}$: given that $E_j$ has occurred at some trial the probability of $E_k$ at the next trial.
    \item $a_k$ : probability of $E_k$ at the initial trial 
\end{itemize}
For instance here are the prob. of some sample sequences.
\begin{align*}
    &P\{(E_j,E_k)\} = a_j p_{jk}\\
    &P\{(E_j,E_k,E_r) \} = a_j p_{jk} p_{kr}\\
    \textrm{(and generally) }& P\{(E_{j_0},E_{j_1},...,E_{j_n})\} = a_{j_0} p_{j_0 j_1} p_{j_1 j_2} \hdots p_{j_{n-1} j_n}
\end{align*}

\section{Random Walk}
A random walk is the process by which randomly-moving objects wander away from where they started.
The simplest random walk to understand is a 1-dimensional random walk. Suppose that 
Given a set of events: 
$$ \{\dots -3, -2, -1, 0, 1, 2, 3, \dots\}$$
we have $P_{j,k} = 0$ if $ | j - k | > 1$. For a symmetric random walk we might accordingly have: $ P_{i, j} = 0$\\
$ P_{j, k} = \frac{1}{2}$ if $|j - k| = 1$
Graphically we would draw arrows with labelled probabilities. It is often a good way to think of a random walk as a markov chain as follows: 

\akash{Small figure here}

\begin{definition}
A sequence of trials with possible outcomes $E_1, E_2, \dots$ is called a Markov chain if the probabilities of sample sequeces are defined by: 
$ P(E_{j_0}, E_{j_1}, \dots , E_{j_n}) = a_{j_0}p_{j_0, j_1} \dots p_{j_{n-1} j_n}$ in terms of a probability distribution $\{a_k\}$ for $E_k$ at the initial (or zero-th) trial and fixed conditional probabilities $p_{j, k}$ of $E_k$ given that $E_j$ has occured in the preceding trial.
\end{definition}
where: $E_k$ = states of the system, $a_k$ = the probabilities of $E_k$ at the initial trial $P_{j, k}$ the probabilities of the transition from $E_j$ to $E_k$

Furthermore, the matrix (finite or infinite) of transition probabilites: 
\begin{align*}
    \mathbf{P} = \begin{bmatrix} 
                    P_{11} & P_{12} & P_{13} & \dots \\
                    P_{21} & P_{22} & P_{23} & \dots \\
                    P_{31} & P_{32} & P_{33} & \dots \\
                    \vdots & \vdots & \vdots & \ddots \\
                \end{bmatrix}
\end{align*}
is a square matrix with non-negative elements and unit row sums. Such a matrix is called a \underline{Stochastic Matrix}.

Any stochastic matrix with initial distribution $\{a_k\}$ completely defines a markov chain with states $E_1, E_2, \dots$

\begin{example}
There are only two possible states $E_1$ and $E_2$. The matrix of transition probabilities is: 
\begin{align}
    \mathbf{P} = \begin{bmatrix} 
                 1 - p & p \\
                 \alpha & 1 - \alpha \\
                 \end{bmatrix}
\end{align}
or in graphical form: 
\akash{Add short figure}
\end{example}

\begin{remark}
This chain could be realized by the following notion of a particle moving along the x-axis. 
It's absolute speed remains constant but the direction of the motion can be reversed. 
The system is in state $E_1$, if the particle moves in the positive direction and in state $E_2$ if the motion is to the left.
Then $p$ is the probability of a reversal when the particle moves to the right and $\alpha$ is the probability of the reversal when the particle moves to the left.
\end{remark}

\begin{example}[Random walks with Absorbing barriers]

\akash{Add short figure}
\begin{align}
    \mathbf{P} = \begin{bmatrix}
    1 & 0 & 0 & 0 \dots 0 & 0 & 0 \\
    q & 0 & p & 0 \dots 0 & 0 & 0 \\
    \vdots & \vdots & \vdots & \dots & \vdots & \vdots\\
    0 & 0 & 0 & 0 \dots q & 0 & p \\
    0 & 0 & 0 & 0 \dots 0 & 0 & 1
    \end{bmatrix}
\end{align}
\begin{itemize}
\item Each of the "interior" states $E_1, \dots, E_{n-1}$ admit transitions only to its left neighbor (with probability $P$) and its right neighbor (with probability $Q$)
\item No transition is possible form $E_0$ or $E_n$ to any other statye. Once $E_0$ or $E_n$ is reached, the system stays there forever
\end{itemize}
\end{example}

\begin{example}[Reflecting barriers]
\akash{Add another figure here}
\begin{align}
    \mathbf{P} = \begin{bmatrix} 
    q & p & 0 & 0 & \dots & 0 & 0 & 0 \\
    q & 0 & p & 0 & \dots & 0 & 0 & 0 \\
    \vdots & \vdots & \vdots & \dots & \vdots & \vdots\\
    0 & 0 & 0 & 0 & \dots & q & 0 & p \\
    0 & 0 & 0 & 0 & \dots & 0 &q & p \\
    \end{bmatrix}
\end{align}
\end{example}

\begin{example}[Cyclical random walks]

\begin{align}
 \mathbf{P} = \begin{bmatrix} 
    0 & p & 0 & 0 & \dots & 0 & 0 & q \\
    q & 0 & p & 0 & \dots & 0 & 0 & 0 \\
    0 & q & 0 & p & \dots & 0 & 0 & 0 \\
    \vdots & \vdots & \vdots & \dots & \vdots & \vdots\\
    0 & 0 & 0 & 0 & \dots & q & 0 & p \\
    p & 0 & 0 & 0 & \dots & 0 & 0 & q \\
    \end{bmatrix}   
\end{align}
More generally we may permit the transitions between any two states. Let $q_0, q_1, \dots, q_{n-1}$ be respectively the probabilities of staying fixed or moving $1, 2, \dots, n-1$ units to the right where $k$ units to the right is same as $n-k$ units to the left. The P is as shown below:
\begin{align}
    \mathbf{P} = \begin{bmatrix}
    q_0 & q_1 & q_2 & \dots & q_{n-2} & q_{n-1} \\
    q_{n-1} & q_0 & q_1 & \dots & q_{n-3} & q_{n-2} \\
    \vdots & \vdots & \vdots & \dots & \vdots & \vdots \\
    q_1 & q_2 & q_3 & \dots & q_{n-1} & q_0
    \end{bmatrix} 
\end{align}
\end{example}

\section{Higher Transition Probabilities}

Denoted by $P_{jk}^l$ the probability of a transition form $E_j$ to $E_k$ in exact $l$ steps. This is the sum of the probabilities of all possible paths $E_j, E_{j-1}, \dots, E_{j-{l-1}}, E_k$, i.e., 
\begin{align}
    P_{jk}^l = \sum_{v \in (j_1, j_{l-1})} \mathbf{P} {(E_v)}
\end{align}

In particular $P_{jk}^1$ = $P_{jk}$ and $P_{jk}^2 = \sum_s P_{js} P_{sk}$. 
We define \[P_{jk}^{(j)} = \begin{cases} \mbox{1,} & \mbox{if } j = k \\ \mbox{0,} & \mbox{if $j \neq k$} \end{cases} \]
and recursively we have:
\begin{align}
    P_{jk}^{i+1} = \sum_s P_{js}P_{sk}^i
\end{align}
In fact, if we arrange $P_{jk}^l$ into a matrix denoted by $\mathbf{P}^l$, then $\mathbf{P}^l$ is just the chain product of l identical matrices $\mathbf{P}$.
\begin{example}
For independent trials it is clear without calculation that $\mathbf{P}^l = \mathbf{P} for all l$
\end{example}
